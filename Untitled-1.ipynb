{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ุฏุฑ ุญุงู ุฎูุงูุฏู ู ุงุฏุบุงู ูุงูโูุง ุจุง ุณุชููโูุง ูุดุฎุต ุดุฏู...\n",
      "โ ูุงู anger.csv ุจุง 20069 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: anger\n",
      "โ ูุงู disgust.csv ุจุง 925 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: disgust\n",
      "โ ูุงู fear.csv ุจุง 17624 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: fear\n",
      "โ ูุงู joy.csv ุจุง 28024 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: joy\n",
      "โ ูุงู sad.csv ุจุง 34328 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: sad\n",
      "โ ูุงู surprise.csv ุจุง 12859 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: surprise\n",
      "\n",
      "------------------------------------\n",
      "โ ุงุฏุบุงู ุจุง ููููุช ุงูุฌุงู ุดุฏ. ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง: 113829\n",
      "\n",
      "ต ุณุทุฑ ุชุตุงุฏู ุงุฒ ูุฌููุนู ุฏุงุฏู ููุง:\n",
      "                                             Text_Content Sentiment_Label\n",
      "106222  ุจูุงุฑู ุฌุงู ุชุชุฑ ุจุฒู ูุฎุงุฒู ุขูููุงฺฉ ูู ุณุฑฺฏุฑุฏุงู ุดุฏ...        surprise\n",
      "73337    ุงฺฏุฑ ูุฎูุงุณุช ูฺฏูุช ุฑุง ุจุฏุฏ! #ุฏุฑูุบ_ููููุน \\nุงู...             sad\n",
      "50737   ูููุง ุจุฒุฑฺฏ ูุงุ ุงุฑุจุงุจ ุฎูุจ ุฎูุจโูุงุ ุขุฒุงุฏูโ ุงุฒ ู...             joy\n",
      "20100     ุชุง ุญุงูุง ุชู ุขูู ุจู ุฎูุฏุช ูฺฏุงู ฺฉุฑุฏ ู ุงูู ฺูุฑู...         disgust\n",
      "50393   ุงูุดุจ ุฏุงุดุชู ุชุฑุงูู ุณุฑุฒูู ูู ุงุฒ ุฏุงูุฏ ุณุฑุฎูุด ุฎูุงูู...             joy\n",
      "\n",
      "ุชูุฒุน ุงุญุณุงุณุงุช:\n",
      "Sentiment_Label\n",
      "sad         34328\n",
      "joy         28024\n",
      "anger       20069\n",
      "fear        17624\n",
      "surprise    12859\n",
      "disgust       925\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ุชฺฉุฑุงุฑ ุญุฐู ุดุฏู: 310\n",
      "\n",
      "โ ุฏุงุฏูโูุง ุงุฏุบุงู ุดุฏู ุฏุฑ ูุงู 'persian_tweets_merged.csv' ุฐุฎุฑู ุดุฏูุฏ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ูุงู ูุงูโูุง CSV \n",
    "file_names = {\n",
    "    'anger': 'anger.csv',\n",
    "    'disgust': 'disgust.csv',\n",
    "    'fear': 'fear.csv',\n",
    "    'joy': 'joy.csv',\n",
    "    'sad': 'sad.csv',\n",
    "    'surprise': 'surprise.csv'\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "print(\"ุฏุฑ ุญุงู ุฎูุงูุฏู ู ุงุฏุบุงู ูุงูโูุง ุจุง ุณุชููโูุง ูุดุฎุต ุดุฏู...\")\n",
    "\n",
    "for sentiment, file_name in file_names.items():\n",
    "    try:\n",
    "        # 1. ุฎูุงูุฏู ูุงู ุจุง ูุฑุถ ูุฌูุฏ ูุฏุฑ (header=0)\n",
    "        df_temp = pd.read_csv(file_name, encoding='utf-8')\n",
    "        \n",
    "        # 2. ุงูุชุฎุงุจ ุณุชููโูุง ุงุตู ู ุชุบุฑ ูุงู ุณุชูู ูุชู ุจุฑุง ฺฉูพุงุฑฺฺฏ\n",
    "        # ูุง ููุท ุณุชููโูุง 'tweet' ู 'emotion' ุฑุง ูุงุฒ ุฏุงุฑู.\n",
    "        df_temp = df_temp[['tweet', 'emotion']]\n",
    "        \n",
    "        # ูฺฉุชู: ฺูู ูุฑ ูุงู ููุท ุดุงูู ฺฉ ููุน ุงุญุณุงุณ (ุจุฑ ุงุณุงุณ ูุงู ูุงู) ุงุณุชุ \n",
    "        # ุณุชูู 'emotion' ุฏุฑ ูุงูุน ููุท ฺฉ ููุฏุงุฑ ุซุงุจุช (ูุซู 'anger') ุฎูุงูุฏ ุฏุงุดุช.\n",
    "        # ูุง ุงุฒ ุณุชูู 'emotion' ุงุตู ุงุณุชูุงุฏู ู ฺฉูู ฺฉู ุฏุฑ ุฏุชุงุณุช ูุฌูุฏ ุฏุงุฑุฏ.\n",
    "\n",
    "        df_temp = df_temp.rename(columns={'tweet': 'Text_Content', 'emotion': 'Sentiment_Label'})\n",
    "        \n",
    "        all_data.append(df_temp)\n",
    "        print(f\"โ ูุงู {file_name} ุจุง {len(df_temp)} ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ. ุงุญุณุงุณ: {sentiment}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"โ ุฎุทุง: ูุงู {file_name} ูพุฏุง ูุดุฏ. ูุทูุฆู ุดูุฏ ฺฉู ุชูุงู ุดุด ูุงู ุฏุฑ ูุณุฑ ุฏุฑุณุช ูุณุชูุฏ.\")\n",
    "    except Exception as e:\n",
    "        print(f\"โ ุฎุทุง ุฏุฑ ุฎูุงูุฏู ูุงู {file_name} ุฑุฎ ุฏุงุฏ: {e}\")\n",
    "\n",
    "# ุงุฏุบุงู ุชูุงู DataFrameูุง ุจู ฺฉ DataFrame ููุง\n",
    "if all_data:\n",
    "    df_merged = pd.concat(all_data, ignore_index=True)\n",
    "    print(\"\\n------------------------------------\")\n",
    "    print(f\"โ ุงุฏุบุงู ุจุง ููููุช ุงูุฌุงู ุดุฏ. ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง: {len(df_merged)}\")\n",
    "    \n",
    "    # ููุงุด ต ุณุทุฑ ุชุตุงุฏู ุงุฒ ูุฌููุนู ุฏุงุฏู ููุง\n",
    "    print(\"\\nต ุณุทุฑ ุชุตุงุฏู ุงุฒ ูุฌููุนู ุฏุงุฏู ููุง:\")\n",
    "    print(df_merged.sample(5))\n",
    "    \n",
    "    # ููุงุด ุชูุฒุน ุจุฑฺุณุจโูุง\n",
    "    print(\"\\nุชูุฒุน ุงุญุณุงุณุงุช:\")\n",
    "    print(df_merged['Sentiment_Label'].value_counts())\n",
    "    \n",
    "    # ุญุฐู ุฑุฏูโูุง ุชฺฉุฑุงุฑ ุงุญุชูุงู\n",
    "    initial_count = len(df_merged)\n",
    "    df_merged.drop_duplicates(subset=['Text_Content', 'Sentiment_Label'], inplace=True)\n",
    "    print(f\"\\nุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ุชฺฉุฑุงุฑ ุญุฐู ุดุฏู: {initial_count - len(df_merged)}\")\n",
    "else:\n",
    "    print(\"ูฺ ูุงู ุจุฑุง ุงุฏุบุงู ูุฌูุฏ ูุฏุงุดุช.\")\n",
    "\n",
    "# ุฐุฎุฑู ุณุงุฒ DataFrame ุงุฏุบุงู ุดุฏู ุฏุฑ ฺฉ ูุงู ุฌุฏุฏ\n",
    "output_file_path = 'persian_tweets_merged.csv'\n",
    "df_merged.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nโ ุฏุงุฏูโูุง ุงุฏุบุงู ุดุฏู ุฏุฑ ูุงู '{output_file_path}' ุฐุฎุฑู ุดุฏูุฏ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03f956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "โ ุณุชูู Clean_Text ุงุฌุงุฏ ุดุฏ.\n",
      "\n",
      "ูููููโุง ุงุฒ ุชูุฒฺฉุงุฑ:\n",
      "ูุชู ุงุตู: ุงฺฏุฑ ูุงูุนุงู ููุงู ูุฑุฏู ูุณุชุฏ ฺฉู ุฏุฑ ุฑูุฒ ุชุดุน ุดูุฏ #ุญุงุฌ_ ูุงุณู ุณููุงู ุจู ุงู ููู ุฏุงุฏุฏ ุงูุชูุงู ุณุฎุช ู ฺฏุฑุฏ ุฑูุฒ ฒธ ุฎุฑุฏุงุฏ ฑดฐฐ ุฑูุฒ #ุงูุชูุงู_ ุณุฎุช ุงุณุช!\n",
      "#ุจู_ุนุดู_ุงูุงู_ุฑุถุง https://t.co/HdBvayzX9W\n",
      "ูุชู ุชูุฒ ุดุฏู: ุงฺฏุฑ ูุงูุนุง ููุงู ูุฑุฏู ูุณุชุฏ ฺฉู ุฏุฑ ุฑูุฒ ุชุดุน ุดูุฏ ูุงุณู ุณููุงู ุจู ุงู ููู ุฏุงุฏุฏ ุงูุชูุงู ุณุฎุช ูโฺฏุฑุฏ ุฑูุฒ ฒธ ุฎุฑุฏุงุฏ ฑดฐฐ ุฑูุฒ ุณุฎุช ุงุณุช\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from hazm import Normalizer\n",
    "\n",
    "# ฑ. ุชุนุฑู ูุฑูุงูุงุฒุฑ Hazm\n",
    "normalizer = Normalizer()\n",
    "\n",
    "def clean_and_normalize(text):\n",
    "    # ุงูู) ุชุจุฏู ุจู ุฑุดุชู (ุฏุฑ ุตูุฑุช ูุงุฒ)\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # ุจ) ุญุฐู ููฺฉโูุง\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # ูพ) ุญุฐู ููุดูโูุง (@username) ู ูุดุชฺฏโูุง (#tag)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # ุช) ุญุฐู ุนูุงุฆู ูฺฏุงุฑุด ู ฺฉุงุฑุงฺฉุชุฑูุง ุงุถุงู ุบุฑ ุงุฒ ุญุฑูู ู ุงุนุฏุงุฏ\n",
    "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text) \n",
    "    \n",
    "    # ุซ) ุญุฐู ูุงุตููโูุง ุงุถุงู\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # ุฌ) ูุฑูุงูโุณุงุฒ ุจุง Hazm\n",
    "    text = normalizer.normalize(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ุงุนูุงู ุชุงุจุน ุชูุฒฺฉุงุฑ ู ูุฑูุงูโุณุงุฒ ุฑู ุณุชูู ูุชู ุงุฏุบุงู ุดุฏู\n",
    "# ุชูุฌู: ุงฺฏุฑ ฺฉุฏ ฑ.ต ุฑุง ุงุฌุฑุง ฺฉุฑุฏู ุจุงุดุฏุ df_merged ุฏุฑ ุญุงูุธู ููุฌูุฏ ุงุณุช.\n",
    "df_merged['Clean_Text'] = df_merged['Text_Content'].apply(clean_and_normalize)\n",
    "\n",
    "# ููุงุด ูุชุงุฌ ุจุฑุง ุงุทููุงู\n",
    "print(\"\\n------------------------------------\")\n",
    "print(\"โ ุณุชูู Clean_Text ุงุฌุงุฏ ุดุฏ.\")\n",
    "print(\"\\nูููููโุง ุงุฒ ุชูุฒฺฉุงุฑ:\")\n",
    "sample_row = df_merged.sample(1)\n",
    "print(f\"ูุชู ุงุตู: {sample_row['Text_Content'].iloc[0]}\")\n",
    "print(f\"ูุชู ุชูุฒ ุดุฏู: {sample_row['Clean_Text'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ae6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "โ ุฏุงุฏูโูุง ุชูุฒ ุดุฏู ู ุขูุงุฏู ูุฏูโุณุงุฒ ุฏุฑ ูุงู 'persian_tweets_cleaned_for_model.csv' ุจุง ุงููฺฉุฏูฺฏ ุณุงุฒฺฏุงุฑ ุฐุฎุฑู ุดุฏูุฏ.\n",
      "ุญุงูุง ู ุชูุงูู ูุงุฑุฏ ูุงุฒ ูุฏูโุณุงุฒ ุดูู.\n"
     ]
    }
   ],
   "source": [
    "# ุงุฌุฑุง ูุฌุฏุฏ ุชูุฒฺฉุงุฑ ุจุฑุง ุงุทููุงู ุงุฒ ูุฌูุฏ ุณุชูู Clean_Text\n",
    "# ูุฑุถ ูโฺฉูู ุชูุฒฺฉุงุฑ ุฏุฑ ุณููู ูุจู ุงุฌุฑุง ุดุฏู ุงุณุช.\n",
    "\n",
    "# ุฐุฎุฑู ุณุงุฒ ููุง DataFrame ุจุง ุณุชููโูุง ุชูุฒ ุดุฏู\n",
    "final_output_file = 'persian_tweets_cleaned_for_model.csv'\n",
    "\n",
    "# index=False: ุจุฑุง ุญุฐู ุณุชููโูุง ุงุถุงู ุงูุฏฺฉุณ\n",
    "# encoding='utf-8-sig': ุงู ููุงู UTF-8 with BOM ุงุณุช ฺฉู ุจุฑุง ุณุงุฒฺฏุงุฑ ุจุง Excel ุจูุชุฑ ุงุณุช.\n",
    "df_merged.to_csv(final_output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nโ ุฏุงุฏูโูุง ุชูุฒ ุดุฏู ู ุขูุงุฏู ูุฏูโุณุงุฒ ุฏุฑ ูุงู '{final_output_file}' ุจุง ุงููฺฉุฏูฺฏ ุณุงุฒฺฏุงุฑ ุฐุฎุฑู ุดุฏูุฏ.\")\n",
    "print(\"ุญุงูุง ู ุชูุงูู ูุงุฑุฏ ูุงุฒ ูุฏูโุณุงุฒ ุดูู.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa9fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ุฏุงุฏูโูุง ุจุง ููููุช ุจุงุฑฺฏุฐุงุฑ ุดุฏูุฏ.\n",
      "\n",
      "ุณุชููโูุง ูุนู ูุจู ุงุฒ ุญุฐู:\n",
      "['Text_Content', 'Sentiment_Label', 'Clean_Text']\n",
      "โ ุณุชููโูุง ุงุถุงู ุญุฐู ุดุฏูุฏ. DataFrame ุจู 2 ุณุชูู ฺฉุงูุด ุงูุช.\n",
      "\n",
      "โ ูุฌููุนู ุฏุงุฏู ุจููู ุดุฏู ุฏุฑ ูุงู 'persian_tweets_optimized_for_training.csv' ุฐุฎุฑู ุดุฏ.\n",
      "ุงู ูุงู ููุท ุดุงูู ุณุชููโูุง Clean_Text ู Sentiment_Label ุงุณุช.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ูุงู ูุงู ููุง ฺฉู ูุจูุงู ุณุงุฎุชู\n",
    "file_path_cleaned = 'persian_tweets_cleaned_for_model.csv'\n",
    "\n",
    "# ฑ. ุจุงุฑฺฏุฐุงุฑ ูุงู (ุจุง ุงุทููุงู ุงุฒ ุงููฺฉุฏูฺฏ)\n",
    "try:\n",
    "    df_final = pd.read_csv(file_path_cleaned, encoding='utf-8-sig')\n",
    "    print(\"โ ุฏุงุฏูโูุง ุจุง ููููุช ุจุงุฑฺฏุฐุงุฑ ุดุฏูุฏ.\")\n",
    "except Exception as e:\n",
    "    print(f\"โ ุฎุทุง ุฏุฑ ุจุงุฑฺฏุฐุงุฑ ูุงู ุฑุฎ ุฏุงุฏ: {e}\")\n",
    "    # ุงฺฏุฑ ุฏุฑ ุจุงุฑฺฏุฐุงุฑ ูุดฺฉู ุฏุงุฑุฏุ ููุท encoding='utf-8' ุฑุง ุงูุชุญุงู ฺฉูุฏ.\n",
    "    df_final = pd.read_csv(file_path_cleaned, encoding='utf-8')\n",
    "\n",
    "\n",
    "# ฒ. ููุงุด ุณุชููโูุง ูุนู ุจุฑุง ุชุฃุฏ\n",
    "print(\"\\nุณุชููโูุง ูุนู ูุจู ุงุฒ ุญุฐู:\")\n",
    "print(df_final.columns.tolist())\n",
    "\n",
    "# ณ. ุญุฐู ุณุชูู Text_Content (ู ูุฑ ุณุชูู ุงุถุงู ุฏฺฏุฑ ฺฉู ูุงุฒ ูุณุช)\n",
    "# ูุง ููุท ุณุชููโูุง Clean_Text ู Sentiment_Label ุฑุง ูฺฏู ูโุฏุงุฑู.\n",
    "columns_to_keep = ['Clean_Text', 'Sentiment_Label']\n",
    "df_optimized = df_final[columns_to_keep]\n",
    "\n",
    "print(f\"โ ุณุชููโูุง ุงุถุงู ุญุฐู ุดุฏูุฏ. DataFrame ุจู {len(df_optimized.columns)} ุณุชูู ฺฉุงูุด ุงูุช.\")\n",
    "\n",
    "# ด. ุฐุฎุฑู ุณุงุฒ ููุง ู ุจููู ุณุงุฒ ุดุฏู\n",
    "optimized_file_path = 'persian_tweets_optimized_for_training.csv'\n",
    "df_optimized.to_csv(optimized_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nโ ูุฌููุนู ุฏุงุฏู ุจููู ุดุฏู ุฏุฑ ูุงู '{optimized_file_path}' ุฐุฎุฑู ุดุฏ.\")\n",
    "print(\"ุงู ูุงู ููุท ุดุงูู ุณุชููโูุง Clean_Text ู Sentiment_Label ุงุณุช.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ********** ฑ. ุชูุธูุงุช ุงููู **********\n",
    "# ฺฉูุฏ API \n",
    "MY_CEREBRAS_API_KEY = \"PLACE_YOUR_ACTUAL_API_KEY_HERE\" \n",
    "\n",
    "# ูุงู ูุฏู\n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "\n",
    "# ูุงูโูุง ุฏุงุฏู\n",
    "FINAL_FILE_NAME = 'cerebras_predictions_final.csv'\n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "\n",
    "try:\n",
    "    # ุณุงุฎุช ฺฉูุงูุช Cerebras\n",
    "    client = Cerebras(api_key=MY_CEREBRAS_API_KEY)\n",
    "    print(f\"โ ฺฉูุงูุช Cerebras ุจุง ูุฏู {MODEL_NAME} ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\")\n",
    "except Exception as e:\n",
    "    print(f\"โ ุฎุทุง ุงุชุตุงู ุจู Cerebras. ุขุง ฺฉูุฏ API ุฏุฑุณุช ุงุณุชุ: {e}\")\n",
    "\n",
    "# ********** ฒ. ุชุนุฑู ุชุงุจุน ุชุญูู **********\n",
    "def analyze_sentiment_cerebras(text):\n",
    "    # Prompt Engineering: ุฏุณุชูุฑุงูุนูู ุฏูู ุจู ูุฏู Instruct\n",
    "    prompt = f\"ูุชู ุชูุช ูุงุฑุณ ุฒุฑ ุฑุง ุชุญูู ฺฉุฑุฏู ู ุงุญุณุงุณ ุขู ุฑุง **ุฏููุง** ุจุง ฺฉ ุงุฒ ุงู ถ ฺฉููู ุงูฺฏูุณ ู ุจุง ุญุฑูู ฺฉูฺฺฉ ุจุฑฺฏุฑุฏุงู: {', '.join(EMOTIONS)}. ุงุฒ ูุฑฺฏููู ุชูุถุญุ ููู ููู ุง ูุชู ุงุถุงู ุฎูุฏุฏุงุฑ ฺฉู ู **ููุท ฺฉ ฺฉููู** ุฑุง ุจุฑฺฏุฑุฏุงู.\\nูุชู: \\\"{text}\\\"\\nุงุญุณุงุณ:\"\n",
    "\n",
    "    try:\n",
    "        # ูุฑุงุฎูุงู API\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=MODEL_NAME,\n",
    "            max_completion_tokens=5, # 5 ุชูฺฉู ุจุฑุง ููุท ฺฉ ฺฉููู\n",
    "            temperature=0.01, # ุฏูุง ุฑุง ุจุณุงุฑ ูพุงู ูโุขูุฑู ุชุง ูพุงุณุฎ ููุท ุฏุณุชูุฑ ุฑุง ุงุฌุฑุง ฺฉูุฏ\n",
    "            top_p=0.8,\n",
    "            # stream=False: ุจู ุทูุฑ ูพุด ูุฑุถ ุฏุฑ SDK ุบุฑูุนุงู ุงุณุช\n",
    "        )\n",
    "\n",
    "        # ุงุณุชุฎุฑุงุฌ ูพุงุณุฎ\n",
    "        prediction_raw = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "        # ุชูุงุด ุจุฑุง ุชุทุจู ูพุงุณุฎ ูุฏู ุจุง ฺฉ ุงุฒ 6 ุจุฑฺุณุจ ูุง\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotion in prediction_raw:\n",
    "                return emotion\n",
    "\n",
    "        # ุงฺฏุฑ ูุฏู ฺุฒ ุบุฑ ุงุฒ 6 ฺฉููู ุจุฑฺฏุฑุฏุงูุฏ\n",
    "        return \"Unknown\" \n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e).lower()\n",
    "        if \"rate limit\" in error_message or \"429\" in error_message:\n",
    "            print(f\"\\n๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) Cerebras ูุนุงู ุดุฏ! ฑฐ ุฏููู ุตุจุฑ ูโฺฉูู...\")\n",
    "            time.sleep(600) \n",
    "            return \"Rate_Limited\" \n",
    "            \n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# ********** ณ. ุดุฑูุน ูพุฑุฏุงุฒุด ุฏุณุชูโุง **********\n",
    "\n",
    "# ุจุงุฑฺฏุฐุงุฑ ูุฌููุนู ุฏุงุฏู ุจููู ุดุฏู (ู ุง ุงุฏุงูู ฺฉุงุฑ ุงุฒ ูุงู inprogress)\n",
    "try:\n",
    "    df_llm = pd.read_csv('cerebras_predictions_inprogress.csv', encoding='utf-8-sig')\n",
    "    print(\"ุงุฏุงูู ฺฉุงุฑ ุงุฒ ูุงู inprogress...\")\n",
    "except FileNotFoundError:\n",
    "    df_llm = pd.read_csv('persian_tweets_optimized_for_training.csv', encoding='utf-8-sig')\n",
    "    df_llm['Cerebras_Prediction'] = 'Not_Analyzed' # ุณุชูู ุฌุฏุฏ\n",
    "\n",
    "\n",
    "# ููุชุฑ ฺฉุฑุฏู ุฑฺฉูุฑุฏูุง ฺฉู ูููุฒ ุชุญูู ูุดุฏูโุงูุฏ\n",
    "remaining_texts_df = df_llm[df_llm['Cerebras_Prediction'].isin(['Not_Analyzed', 'Rate_Limited'])]\n",
    "print(f\"ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ุชุญูู: {len(remaining_texts_df)}\")\n",
    "\n",
    "# ุญููู ุฒุฏู ุจุฑ ุฑู ุฏุงุฏูโูุง\n",
    "for index, row in tqdm(remaining_texts_df.iterrows(), total=len(remaining_texts_df), desc=\"ุชุญูู ุจุง Qwen3-235B\"):\n",
    "    result = analyze_sentiment_cerebras(row['Clean_Text'])\n",
    "    \n",
    "    # ุจูโุฑูุฒุฑุณุงู DataFrame ุงุตู\n",
    "    df_llm.loc[index, 'Cerebras_Prediction'] = result\n",
    "    \n",
    "    # *ุฐุฎุฑูโุณุงุฒ ุฏูุฑูโุง ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุงุฒ ุฏุณุช ุฑูุชู ุฏุงุฏูโูุง*\n",
    "    if (index + 1) % 500 == 0:\n",
    "        df_llm.to_csv('cerebras_predictions_inprogress.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # ุงฺฏุฑ ุจู Rate Limit ุฑุณุฏูุ ุจุงุฏ ุญููู ุฑุง ูุชููู ฺฉูู ู ุฐุฎุฑู ููุง ุฑุง ุงูุฌุงู ุฏูู.\n",
    "    if result == \"Rate_Limited\":\n",
    "        print(\"ุจู ูุญุฏูุฏุช ุฑูุฒุงูู ุฑุณุฏุฏ. ฺฉุงุฑ ูุชููู ู ุฐุฎุฑู ููุง ุดุฏ.\")\n",
    "        break\n",
    "        \n",
    "# ุฐุฎุฑู ููุง\n",
    "df_llm.to_csv(FINAL_FILE_NAME, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nโ ุชุญูู ุจุง Cerebras/Qwen API ุจู ูพุงุงู ุฑุณุฏ ู ูุชุงุฌ ููุง ุฏุฑ '{FINAL_FILE_NAME}' ุฐุฎุฑู ุดุฏูุฏ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f549a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 1 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n",
      "ุงุฏุงูู ฺฉุงุฑ ุงุฒ ูุงู 'inprogress'...\n",
      "ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ุชุญูู: 109519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุชุญูู ุจุง Qwen3-235B:   0%|          | 2/109519 [00:23<302:49:15,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 1 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 2 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุชุญูู ุจุง Qwen3-235B:   0%|          | 34/109519 [03:13<66:05:03,  2.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 2 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 3 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n",
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 3 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 4 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n",
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 4 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 5 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุชุญูู ุจุง Qwen3-235B:   0%|          | 100/109519 [11:36<464:08:10, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 5 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 6 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุชุญูู ุจุง Qwen3-235B:   0%|          | 101/109519 [11:40<361:16:22, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 6 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 7 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n",
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 7 ูุนุงู ุดุฏ!\n",
      "\n",
      "โ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู 8 ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ุชุญูู ุจุง Qwen3-235B:   0%|          | 101/109519 [11:47<213:03:17,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู 8 ูุนุงู ุดุฏ!\n",
      "\n",
      "๐๐ ุชูุงู ฺฉูุฏูุง ููุฌูุฏ ุงุณุชูุงุฏู ุดุฏูุฏ ุง ุจู ูุญุฏูุฏุช ุฑุณุฏูุฏ. ุงูุฑูุฒ ฺฉุงุฑ ูุชููู ุดุฏ. ๐๐\n",
      "ุชูุงู ฺฉูุฏูุง ููุฌูุฏ ุจู ูุญุฏูุฏุช ุฎูุฑุฏูุฏ. ฺฉุงุฑ ูุชููู ู ุฐุฎุฑู ููุง ุดุฏ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "โ ุชุญูู ุจู ูพุงุงู ุฑุณุฏ ู ูุชุงุฌ ุฏุฑ 'cerebras_predictions_final.csv' ุฐุฎุฑู ุดุฏูุฏ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ********** ฑ. ุชูุธูุงุช ุงููู ู ูุฏู **********\n",
    "\n",
    "CEREBRAS_API_KEYS = [\n",
    "    \"\",  # ฺฉูุฏ ุงูู (ุงุตู)\n",
    "    \"\", # ฺฉูุฏ ุฏูู (ุงุถุงู ุจุฑุง ุชุณุฑุน ฺฉุงุฑ)\n",
    "    \n",
    "    # ุงฺฏุฑ ฺฉูุฏูุง ุจุดุชุฑ ุฏุงุฑุฏุ ุงูุฌุง ุงุถุงูู ฺฉูุฏ\n",
    "]\n",
    "\n",
    "# ูุงู ูุฏู \n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "\n",
    "# ูุงูโูุง ุฏุงุฏู ู ูุณุช ุงุญุณุงุณุงุช\n",
    "FINAL_FILE_NAME = 'cerebras_predictions_final.csv'\n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "# ูุชุบุฑูุง ุณุฑุงุณุฑ ุจุฑุง ูุฏุฑุช ฺฉูุงูุช ู ฺฉูุฏ\n",
    "current_key_index = 0\n",
    "client = None\n",
    "\n",
    "\n",
    "# ********** ฒ. ุชูุงุจุน ูุฏุฑุช ฺฉูุฏ ู ฺฉูุงูุช **********\n",
    "\n",
    "def get_next_client():\n",
    "    \"\"\"ฺฉ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ API ุจุนุฏ ุฑุง ุจุฑูโฺฏุฑุฏุงูุฏ.\"\"\"\n",
    "    global current_key_index, client\n",
    "    \n",
    "    # ุจุฑุฑุณ ฺฉูุฏ ฺฉู ุขุง ฺฉูุฏ ุฏฺฏุฑ ุจุฑุง ุงุณุชูุงุฏู ุจุงู ูุงูุฏู ุงุณุชุ\n",
    "    if current_key_index >= len(CEREBRAS_API_KEYS):\n",
    "        print(\"\\n๐๐ ุชูุงู ฺฉูุฏูุง ููุฌูุฏ ุงุณุชูุงุฏู ุดุฏูุฏ ุง ุจู ูุญุฏูุฏุช ุฑุณุฏูุฏ. ุงูุฑูุฒ ฺฉุงุฑ ูุชููู ุดุฏ. ๐๐\")\n",
    "        return None \n",
    "    \n",
    "    # ุงุณุชูุงุฏู ุงุฒ ฺฉูุฏ ูุนู\n",
    "    api_key = CEREBRAS_API_KEYS[current_key_index]\n",
    "    \n",
    "    try:\n",
    "        # ุฏุฑ ุงูุฌุง ูุง ูุณุชููุงู ฺฉูุฏ ุฑุง ุจู ุฌุง ุงุณุชูุงุฏู ุงุฒ os.environ ุจู Cerebras ูพุงุณ ูโุฏูู\n",
    "        client = Cerebras(api_key=api_key)\n",
    "        print(f\"\\nโ ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุดูุงุฑู {current_key_index + 1} ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"โ ุฎุทุง ุงุชุตุงู ุจุง ฺฉูุฏ {current_key_index + 1}: {e}\")\n",
    "        current_key_index += 1 \n",
    "        return get_next_client() # ุชูุงุด ูุฌุฏุฏ ุจุง ฺฉูุฏ ุจุนุฏ\n",
    "\n",
    "\n",
    "def analyze_sentiment_cerebras(text):\n",
    "    \"\"\"ุชุญูู ุงุญุณุงุณุงุช ุจุง Cerebras API ู ูุฏุฑุช ุฎุทุงูุง Rate Limit.\"\"\"\n",
    "    global current_key_index, client\n",
    "    \n",
    "    if client is None:\n",
    "        return \"All_Keys_Used\"\n",
    "    \n",
    "    # Prompt Engineering: ุฏุณุชูุฑุงูุนูู ุฏูู ุจู ูุฏู Instruct\n",
    "    prompt = (\n",
    "        f\"ูุชู ุชูุช ูุงุฑุณ ุฒุฑ ุฑุง ุชุญูู ฺฉุฑุฏู ู ุงุญุณุงุณ ุขู ุฑุง **ุฏููุง** ุจุง ฺฉ ุงุฒ ุงู ถ ฺฉููู ุงูฺฏูุณ ู ุจุง ุญุฑูู ฺฉูฺฺฉ ุจุฑฺฏุฑุฏุงู: {', '.join(EMOTIONS)}. \"\n",
    "        f\"ุงุฒ ูุฑฺฏููู ุชูุถุญุ ููู ููู ุง ูุชู ุงุถุงู ุฎูุฏุฏุงุฑ ฺฉู ู **ููุท ฺฉ ฺฉููู** ุฑุง ุจุฑฺฏุฑุฏุงู.\\n\"\n",
    "        f\"ูุชู: \\\"{text}\\\"\\nุงุญุณุงุณ:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # ูุฑุงุฎูุงู API\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=MODEL_NAME,\n",
    "            max_completion_tokens=5, \n",
    "            temperature=0.01,\n",
    "            top_p=0.8,\n",
    "        )\n",
    "\n",
    "        # ุงุณุชุฎุฑุงุฌ ูพุงุณุฎ\n",
    "        prediction_raw = response.choices[0].message.content.strip().lower()\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotion in prediction_raw:\n",
    "                return emotion\n",
    "        return \"Unknown\" # ุงฺฏุฑ ูพุงุณุฎ ูุฏู ุฎุงุฑุฌ ุงุฒ 6 ุฏุณุชู ูุง ุจูุฏ\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e).lower()\n",
    "        if \"rate limit\" in error_message or \"429\" in error_message or \"too many requests\" in error_message:\n",
    "            # ุงฺฏุฑ ุจู Rate Limit ุฎูุฑุฏุ ฺฉูุฏ ุฑุง ุนูุถ ฺฉู!\n",
    "            print(f\"\\n๐ ูุญุฏูุฏุช ูุฑุฎ (Rate Limit) ุจุฑุง ฺฉูุฏ ุดูุงุฑู {current_key_index + 1} ูุนุงู ุดุฏ!\")\n",
    "            current_key_index += 1 \n",
    "            client = get_next_client() # ุชุนุฑู ฺฉูุงูุช ุฌุฏุฏ ุจุง ฺฉูุฏ ุจุนุฏ\n",
    "            \n",
    "            if client is None:\n",
    "                 return \"All_Keys_Used\"\n",
    "            \n",
    "            # ุจุง ฺฉูุฏ ุฌุฏุฏ ุฏูุจุงุฑู ุชูุงุด ฺฉู\n",
    "            return analyze_sentiment_cerebras(text)\n",
    "            \n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# ********** ณ. ุดุฑูุน ูพุฑุฏุงุฒุด ุฏุณุชูโุง **********\n",
    "\n",
    "# ุชุนุฑู ฺฉูุงูุช ุงููู\n",
    "client = get_next_client()\n",
    "if client is None:\n",
    "    print(\"ูฺ ฺฉูุฏ ูุนุงู ูพุฏุง ูุดุฏ. ูุทูุงู ฺฉูุฏูุง API ุฑุง ุจุฑุฑุณ ฺฉูุฏ.\")\n",
    "\n",
    "# ุจุงุฑฺฏุฐุงุฑ ูุฌููุนู ุฏุงุฏู (ุงุฏุงูู ฺฉุงุฑ ุงุฒ ูุงู inprogress ุง ุดุฑูุน ุงุฒ ูุงู ุจููู ุดุฏู)\n",
    "try:\n",
    "    df_llm = pd.read_csv('cerebras_predictions_inprogress.csv', encoding='utf-8-sig')\n",
    "    print(\"ุงุฏุงูู ฺฉุงุฑ ุงุฒ ูุงู 'inprogress'...\")\n",
    "except FileNotFoundError:\n",
    "    df_llm = pd.read_csv('persian_tweets_optimized_for_training.csv', encoding='utf-8-sig')\n",
    "    df_llm['Cerebras_Prediction'] = 'Not_Analyzed' # ุณุชูู ุฌุฏุฏ\n",
    "\n",
    "\n",
    "# ููุชุฑ ฺฉุฑุฏู ุฑฺฉูุฑุฏูุง ฺฉู ูููุฒ ุชุญูู ูุดุฏูโุงูุฏ\n",
    "remaining_texts_df = df_llm[df_llm['Cerebras_Prediction'].isin(['Not_Analyzed', 'Rate_Limited'])]\n",
    "print(f\"ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ุชุญูู: {len(remaining_texts_df)}\")\n",
    "\n",
    "\n",
    "# ุญููู ุฒุฏู ุจุฑ ุฑู ุฏุงุฏูโูุง\n",
    "for index, row in tqdm(remaining_texts_df.iterrows(), total=len(remaining_texts_df), desc=\"ุชุญูู ุจุง Qwen3-235B\"):\n",
    "    \n",
    "    # ุงฺฏุฑ ฺฉูุงูุช ูุงูุนุชุจุฑ ุงุณุชุ ฺฉุงุฑ ุฑุง ูุชููู ฺฉู\n",
    "    if client is None:\n",
    "        break\n",
    "        \n",
    "    result = analyze_sentiment_cerebras(row['Clean_Text'])\n",
    "    \n",
    "    # ุจูโุฑูุฒุฑุณุงู DataFrame ุงุตู\n",
    "    df_llm.loc[index, 'Cerebras_Prediction'] = result\n",
    "    \n",
    "    # *ุฐุฎุฑูโุณุงุฒ ุฏูุฑูโุง ุจุฑุง ุฌููฺฏุฑ ุงุฒ ุงุฒ ุฏุณุช ุฑูุชู ุฏุงุฏูโูุง*\n",
    "    if (index + 1) % 500 == 0:\n",
    "        df_llm.to_csv('cerebras_predictions_inprogress.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # ุงฺฏุฑ ุชูุงู ฺฉูุฏูุง ุจู ูุญุฏูุฏุช ุฎูุฑุฏูุฏุ ฺฉุงุฑ ูุชููู ูโุดูุฏ.\n",
    "    if result == \"All_Keys_Used\":\n",
    "        print(\"ุชูุงู ฺฉูุฏูุง ููุฌูุฏ ุจู ูุญุฏูุฏุช ุฎูุฑุฏูุฏ. ฺฉุงุฑ ูุชููู ู ุฐุฎุฑู ููุง ุดุฏ.\")\n",
    "        break\n",
    "        \n",
    "# ุฐุฎุฑู ููุง (ุดุงูู ูุชุงุฌ ฺฉุงูู ุง ูููุช)\n",
    "df_llm.to_csv(FINAL_FILE_NAME, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nโ ุชุญูู ุจู ูพุงุงู ุฑุณุฏ ู ูุชุงุฌ ุฏุฑ '{FINAL_FILE_NAME}' ุฐุฎุฑู ุดุฏูุฏ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f03cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ูุฑุญูู ฑ: ุงุฌุงุฏ ฺฉูุงูุช ููููุช ุขูุฒ.\n",
      "\n",
      "โ ุฎุทุง ุงุญุฑุงุฒ ููุช ุง ุงุชุตุงู ุฑุฎ ุฏุงุฏ:\n",
      "Error code: 429 - {'message': \"We're experiencing high traffic right now! Please try again soon.\", 'type': 'too_many_requests_error', 'param': 'queue', 'code': 'queue_exceeded'}\n"
     ]
    }
   ],
   "source": [
    "from cerebras.cloud.sdk import Cerebras\n",
    "import os\n",
    "\n",
    "# !!! ฺฉูุฏ ุฎูุฏ ุฑุง ุฏูุจุงุฑู ุงูุฌุง ุฌุงฺฏุฒู ฺฉูุฏ !!!\n",
    "MY_CEREBRAS_API_KEY = \"csk-n9d4tvp6m4855cn93yw5r4cr2ev2kcedy93neh4rhfvecd5j\"\n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "test_text = \"ูุงูุนุงู ุงุฒ ุนููฺฉุฑุฏ ุงู ูุญุตูู ุฌุฏุฏ ุฑุงุถ ูุณุชู ู ุญุณ ุฎูุจ ุฏุงุฑู.\"\n",
    "test_prompt = (\n",
    "    f\"ูุชู ุชูุช ูุงุฑุณ ุฒุฑ ุฑุง ุชุญูู ฺฉุฑุฏู ู ุงุญุณุงุณ ุขู ุฑุง **ุฏููุง** ุจุง ฺฉ ุงุฒ ุงู ถ ฺฉููู ุงูฺฏูุณ ู ุจุง ุญุฑูู ฺฉูฺฺฉ ุจุฑฺฏุฑุฏุงู: {', '.join(EMOTIONS)}. \"\n",
    "    f\"ุงุฒ ูุฑฺฏููู ุชูุถุญุ ููู ููู ุง ูุชู ุงุถุงู ุฎูุฏุฏุงุฑ ฺฉู ู **ููุท ฺฉ ฺฉููู** ุฑุง ุจุฑฺฏุฑุฏุงู.\\n\"\n",
    "    f\"ูุชู: \\\"{test_text}\\\"\\nุงุญุณุงุณ:\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # ฑ. ุงุฌุงุฏ ฺฉูุงูุช\n",
    "    client = Cerebras(api_key=MY_CEREBRAS_API_KEY)\n",
    "    print(\"โ ูุฑุญูู ฑ: ุงุฌุงุฏ ฺฉูุงูุช ููููุช ุขูุฒ.\")\n",
    "    \n",
    "    # ฒ. ุงุฑุณุงู ุฏุฑุฎูุงุณุช\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "            {\"role\": \"user\", \"content\": test_prompt}\n",
    "        ],\n",
    "        model=MODEL_NAME,\n",
    "        max_completion_tokens=5, \n",
    "        temperature=0.01,\n",
    "        top_p=0.8,\n",
    "    )\n",
    "    \n",
    "    # ณ. ููุงุด ูุชุฌู\n",
    "    print(\"โ ูุฑุญูู ฒ: ุงุฑุณุงู ุฏุฑุฎูุงุณุช ู ุฏุฑุงูุช ูพุงุณุฎ ููููุช ุขูุฒ.\")\n",
    "    print(\"\\nูุชุฌู ูุฏู (ุงุญุณุงุณ):\", response.choices[0].message.content.strip())\n",
    "\n",
    "except Exception as e:\n",
    "    # ด. ฺุงูพ ุฎุทุง ุฏูู\n",
    "    print(\"\\nโ ุฎุทุง ุงุญุฑุงุฒ ููุช ุง ุงุชุตุงู ุฑุฎ ุฏุงุฏ:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7298cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "โ ูุงู persian_tweets_optimized_for_training.csv ุจุง 113519 ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ.\n",
      "\n",
      "ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ูููููโฺฏุฑ ูุชูุงุณุจ: 19086\n",
      "  - ุงูุชุฎุงุจ 5797 ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ 'sad'\n",
      "  - ุงูุชุฎุงุจ 4740 ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ 'joy'\n",
      "  - ุงูุชุฎุงุจ 3394 ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ 'anger'\n",
      "  - ุงูุชุฎุงุจ 2978 ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ 'fear'\n",
      "  - ุงูุชุฎุงุจ 2174 ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ 'surprise'\n",
      "\n",
      "------------------------------------\n",
      "โ ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ููุง: 19997\n",
      "โ ุชูุฒุน ุงุญุณุงุณุงุช ููุง (ฒฐK):\n",
      "Sentiment_Label\n",
      "sad         5797\n",
      "joy         4740\n",
      "anger       3394\n",
      "fear        2978\n",
      "surprise    2174\n",
      "disgust      914\n",
      "Name: count, dtype: int64\n",
      "โ ูุงู ููุง 'persian_20k_optimized.csv' ุขูุงุฏู ุดุฏ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ********** ฑ. ุชูุธูุงุช ูุงู **********\n",
    "MERGED_FILE_NAME = 'persian_tweets_optimized_for_training.csv' \n",
    "FINAL_20K_FILE_NAME = 'persian_20k_optimized.csv'\n",
    "TARGET_TOTAL_SIZE = 20000\n",
    "\n",
    "# ********** ฒ. ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง ฑฑณK **********\n",
    "try:\n",
    "    # ุฎูุงูุฏู ูุงู ฑฑณK ุจุง ุณุชููโูุง Clean_Text ู Sentiment_Label\n",
    "    df_full = pd.read_csv(MERGED_FILE_NAME, encoding='utf-8')\n",
    "    print(f\"โ ูุงู {MERGED_FILE_NAME} ุจุง {len(df_full)} ุฑฺฉูุฑุฏ ุจุงุฑฺฏุฐุงุฑ ุดุฏ.\")\n",
    "    # ุงุทููุงู ุงุฒ ุงูฺฉู ููุท ุฑฺฉูุฑุฏูุง ุชูุฒ ุดุฏู ู ุฏุงุฑุง ุจุฑฺุณุจ ุงุณุชูุงุฏู ุดููุฏ\n",
    "    df_full.dropna(subset=['Clean_Text', 'Sentiment_Label'], inplace=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"โ ุฎุทุง: ูุงู '{MERGED_FILE_NAME}' ูพุฏุง ูุดุฏ.\")\n",
    "    exit()\n",
    "\n",
    "# ********** ณ. ุงุณุชุฑุงุชฺ ูููููโฺฏุฑ ุทุจููโุจูุฏ ุดุฏู **********\n",
    "\n",
    "# ุชุนุฑู ุณูู ูุฑ ฺฉูุงุณ ุฏุฑ ููููู ููุง ุจุฑ ุงุณุงุณ ูุญุงุณุจุงุช ุจุงูุง\n",
    "# 1. ฺฉูุงุณ disgust (นฒต ุฑฺฉูุฑุฏ)\n",
    "disgust_df = df_full[df_full['Sentiment_Label'] == 'disgust'].copy()\n",
    "final_sample_df = [disgust_df]\n",
    "remaining_target_size = TARGET_TOTAL_SIZE - len(disgust_df)\n",
    "\n",
    "# 2. ฺฉูุงุณโูุง ุจุงูโูุงูุฏู ุจุฑุง ูููููโฺฏุฑ\n",
    "remaining_classes = ['sad', 'joy', 'anger', 'fear', 'surprise']\n",
    "original_counts = df_full['Sentiment_Label'].value_counts()\n",
    "remaining_total_count = original_counts[remaining_classes].sum()\n",
    "\n",
    "print(f\"\\nุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ูููููโฺฏุฑ ูุชูุงุณุจ: {remaining_target_size}\")\n",
    "\n",
    "for emotion in remaining_classes:\n",
    "    # ูุญุงุณุจู ูุณุจุช ุณูู ุงู ุงุญุณุงุณ ุงุฒ ฺฉู ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู\n",
    "    proportion = original_counts[emotion] / remaining_total_count\n",
    "    \n",
    "    # ูุญุงุณุจู ุชุนุฏุงุฏ ููููู ููุฑุฏ ูุงุฒ ุจุฑุง ุงู ุงุญุณุงุณ\n",
    "    sample_size = int(proportion * remaining_target_size)\n",
    "    \n",
    "    # ูููููโฺฏุฑ ุชุตุงุฏู ู ูุชูุงุณุจ\n",
    "    sample_df = df_full[df_full['Sentiment_Label'] == emotion].sample(\n",
    "        n=sample_size, \n",
    "        random_state=42 # ุจุฑุง ุชฺฉุฑุงุฑูพุฐุฑ\n",
    "    ).copy()\n",
    "    \n",
    "    final_sample_df.append(sample_df)\n",
    "    print(f\"  - ุงูุชุฎุงุจ {sample_size} ุฑฺฉูุฑุฏ ุจุฑุง ุงุญุณุงุณ '{emotion}'\")\n",
    "\n",
    "\n",
    "# 4. ุงุฏุบุงู ููููู ููุง\n",
    "df_final_20k = pd.concat(final_sample_df, ignore_index=True)\n",
    "\n",
    "# 5. ุฐุฎุฑู ููุง\n",
    "df_final_20k[['Clean_Text', 'Sentiment_Label']].to_csv(FINAL_20K_FILE_NAME, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "print(f\"โ ุชุนุฏุงุฏ ุฑฺฉูุฑุฏูุง ููุง: {len(df_final_20k)}\")\n",
    "print(f\"โ ุชูุฒุน ุงุญุณุงุณุงุช ููุง (ฒฐK):\")\n",
    "print(df_final_20k['Sentiment_Label'].value_counts())\n",
    "print(f\"โ ูุงู ููุง '{FINAL_20K_FILE_NAME}' ุขูุงุฏู ุดุฏ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ********** ฑ. ุชูุธูุงุช ุงููู **********\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY_HERE\" \n",
    "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
    "\n",
    "# ูุงู ูุงู ูุฌููุนู ุฏุงุฏู ฺฉูฺฺฉ ฒฐK ุดูุง\n",
    "DATA_FILE_NAME = 'persian_20k_optimized.csv' \n",
    "GEMINI_OUTPUT_FILE = 'gemini_20k_predictions_final.csv'\n",
    "MODEL_NAME_GEMINI = \"gemini-1.5-flash\"\n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "RETRY_DELAY = 15 # ุชุงุฎุฑ 15 ุซุงูู ุง ุฏุฑ ุตูุฑุช ุจุฑุฎูุฑุฏ ุจุง Rate Limit\n",
    "\n",
    "\n",
    "# ********** ฒ. ุชุนุฑู ฺฉูุงูุช ู ุชุงุจุน ุชุญูู **********\n",
    "\n",
    "try:\n",
    "    # ุจุฑุฑุณ ฺฉูุฏ ฺฉู ฺฉูุฏ API ุชูุธู ุดุฏู ุจุงุดุฏ\n",
    "    if not GEMINI_API_KEY or GEMINI_API_KEY == \"YOUR_GEMINI_API_KEY_HERE\":\n",
    "        raise ValueError(\"ูุทูุงู GEMINI_API_KEY ุฑุง ุจุง ฺฉูุฏ ูุงูุน ุฎูุฏ ุฌุงฺฏุฒู ฺฉูุฏ.\")\n",
    "        \n",
    "    client_gemini = genai.Client()\n",
    "    print(f\"โ ฺฉูุงูุช Gemini ุจุง ูุฏู {MODEL_NAME_GEMINI} ุจุง ููููุช ุงุฌุงุฏ ุดุฏ.\")\n",
    "except Exception as e:\n",
    "    print(f\"โ ุฎุทุง ุงุฌุงุฏ ฺฉูุงูุช Gemini: {e}\")\n",
    "    client_gemini = None\n",
    "\n",
    "\n",
    "def analyze_sentiment_gemini(text):\n",
    "    \"\"\"ุชุญูู ุงุญุณุงุณุงุช ุจุง Gemini API ู ูุฏุฑุช ุฎุทุง Rate Limit.\"\"\"\n",
    "    if client_gemini is None:\n",
    "        return \"Client_Error\"\n",
    "        \n",
    "    # ุฏุณุชูุฑ ูพุฑุงููพุช (Prompt) ฺฉู ุงุฒ ูุฏู ูโุฎูุงูุฏ ููุท ฺฉ ุงุฒ ถ ฺฉููู ุฑุง ุจุฑฺฏุฑุฏุงูุฏ.\n",
    "    prompt = (\n",
    "        f\"ูุชู ุชูุช ูุงุฑุณ ุฒุฑ ุฑุง ุชุญูู ฺฉุฑุฏู ู ุงุญุณุงุณ ุขู ุฑุง **ุฏููุง** ุจุง ฺฉ ุงุฒ ุงู ถ ฺฉููู ุงูฺฏูุณ ู ุจุง ุญุฑูู ฺฉูฺฺฉ ุจุฑฺฏุฑุฏุงู: {', '.join(EMOTIONS)}. \"\n",
    "        f\"ููุท ฺฉ ฺฉููู ุฑุง ุจุฑฺฏุฑุฏุงู ู ุงุฒ ูุฑฺฏููู ูุชู ุงุถุงู ุฎูุฏุฏุงุฑ ฺฉู.\\n\"\n",
    "        f\"ูุชู: \\\"{text}\\\"\\nุงุญุณุงุณ:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client_gemini.models.generate_content(\n",
    "            model=MODEL_NAME_GEMINI,\n",
    "            contents=[prompt],\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.01, # ุฏูุง ูพุงู ุจุฑุง ูพุงุณุฎโูุง ุฏููโุชุฑ\n",
    "                max_output_tokens=5, # ุญุฏุงฺฉุซุฑ ต ุชูฺฉู ุจุฑุง ุงุทููุงู ุงุฒ ุฎุฑูุฌ ฺฉ ฺฉููู\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        prediction_raw = response.text.strip().lower()\n",
    "\n",
    "        # ุชุทุจู ูพุงุณุฎ ูุฏู ุจุง ฺฉ ุงุฒ ุจุฑฺุณุจโูุง ููุฑุฏ ูุธุฑ ูุง\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotion in prediction_raw:\n",
    "                return emotion\n",
    "        \n",
    "        # ุงฺฏุฑ ูพุงุณุฎ ูุฏู ูฺ ฺฉ ุงุฒ ถ ฺฉููู ูุจูุฏ\n",
    "        return \"Unknown\" \n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e).lower()\n",
    "        if \"rate limit\" in error_message or \"429\" in error_message:\n",
    "            # ูุฏุฑุช Rate Limit: ุตุจุฑ ู ุณูพุณ Retry (ุชูุงุด ูุฌุฏุฏ)\n",
    "            print(f\"\\n๐ ูุญุฏูุฏุช ูุฑุฎ Gemini! {RETRY_DELAY} ุซุงูู ุตุจุฑ ู ุชูุงุด ูุฌุฏุฏ...\")\n",
    "            time.sleep(RETRY_DELAY)\n",
    "            \n",
    "            # ฺฉ ุจุงุฑ ุชูุงุด ูุฌุฏุฏ\n",
    "            try:\n",
    "                response = client_gemini.models.generate_content(\n",
    "                    model=MODEL_NAME_GEMINI,\n",
    "                    contents=[prompt],\n",
    "                    config=types.GenerateContentConfig(\n",
    "                        temperature=0.01, \n",
    "                        max_output_tokens=5,\n",
    "                    )\n",
    "                )\n",
    "                prediction_raw = response.text.strip().lower()\n",
    "                for emotion in EMOTIONS:\n",
    "                    if emotion in prediction_raw:\n",
    "                        return emotion\n",
    "                return \"Unknown_Retry\"\n",
    "            except:\n",
    "                return \"Rate_Limited\" # ุงฺฏุฑ ุจุงุฒ ูู ุฎุทุง ุฏุงุฏุ ุจู ุนููุงู ูุญุฏูุฏุช ุซุจุช ฺฉู\n",
    "            \n",
    "        return \"API_Error\" # ุณุงุฑ ุฎุทุงูุง API\n",
    "        \n",
    "# ********** ณ. ุดุฑูุน ูพุฑุฏุงุฒุด ุฏุณุชูโุง **********\n",
    "\n",
    "# ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง (ุดุฑูุน ุจุง ูุงู 20K ุฌุฏุฏ)\n",
    "try:\n",
    "    df_merged = pd.read_csv(DATA_FILE_NAME, encoding='utf-8-sig')\n",
    "    \n",
    "    # ุงุทููุงู ุงุฒ ูุฌูุฏ ุณุชููโูุง ูุงุฒู ู ุญุฐู ุฑุฏูโูุง ุจุง Clean_Text ุฎุงู\n",
    "    df_merged.dropna(subset=['Clean_Text', 'Sentiment_Label'], inplace=True)\n",
    "    \n",
    "    # ุขูุงุฏู ุณุงุฒ ุณุชูู ุฌุฏุฏ\n",
    "    if 'Gemini_Prediction' not in df_merged.columns:\n",
    "        df_merged['Gemini_Prediction'] = 'Not_Analyzed'\n",
    "        \n",
    "    # ุจุฑุฑุณ ูุฌูุฏ ูุงู inprogress ุจุฑุง ุงุฏุงูู ฺฉุงุฑ\n",
    "    if os.path.exists('gemini_20k_inprogress.csv'):\n",
    "        df_inprogress = pd.read_csv('gemini_20k_inprogress.csv', encoding='utf-8-sig')\n",
    "        # ุงุฏุบุงู ุจุง ูุงู inprogress ุจุฑุง ุงุฏุงูู ุฏุงุฏู ุงุฒ ุฌุง ฺฉู ูุทุน ุดุฏู ุงุณุช\n",
    "        df_merged.update(df_inprogress[df_inprogress['Gemini_Prediction'] != 'Not_Analyzed'])\n",
    "        print(\"๐ก ุงุฏุงูู ุชุญูู ุงุฒ ุฑู ูุงู inprogress.\")\n",
    "\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"โ ูุงู ุฏุงุฏู '{DATA_FILE_NAME}' ูพุฏุง ูุดุฏ. ูุทูุงู ูุทูุฆู ุดูุฏ ูุงู 20k ุฏุฑ ูพูุดู ูพุฑูฺู ูุฑุงุฑ ุฏุงุฑุฏ.\")\n",
    "    exit()\n",
    "\n",
    "remaining_texts_df = df_merged[df_merged['Gemini_Prediction'] == 'Not_Analyzed']\n",
    "print(f\"ุชุนุฏุงุฏ ฺฉู ุฑฺฉูุฑุฏูุง ุจุงูโูุงูุฏู ุจุฑุง ุชุญูู ุจุง Gemini: {len(remaining_texts_df)}\")\n",
    "\n",
    "# ุญููู ุฒุฏู ุจุฑ ุฑู ุฏุงุฏูโูุง\n",
    "for index, row in tqdm(remaining_texts_df.iterrows(), total=len(remaining_texts_df), desc=\"ุชุญูู ุจุง Gemini 1.5 Flash\"):\n",
    "    \n",
    "    # ูุทูุฆู ูโุดูู ูุชู ุจุฑุง ุชุญูู ุฎุงู ูุณุช\n",
    "    text_to_analyze = row['Clean_Text']\n",
    "    if pd.isna(text_to_analyze) or not text_to_analyze.strip():\n",
    "        result = \"Empty_Text\"\n",
    "    else:\n",
    "        result = analyze_sentiment_gemini(text_to_analyze)\n",
    "    \n",
    "    # ุจูโุฑูุฒุฑุณุงู DataFrame ุงุตู ุจุง ูุชุฌู\n",
    "    df_merged.loc[index, 'Gemini_Prediction'] = result\n",
    "    \n",
    "    # ุฐุฎุฑูโุณุงุฒ ุฏูุฑูโุง ูุฑ 500 ุฑฺฉูุฑุฏ\n",
    "    if (index + 1) % 500 == 0:\n",
    "        df_merged.to_csv('gemini_20k_inprogress.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nุฐุฎุฑูโุณุงุฒ ูููุช ุฏุฑ 'gemini_20k_inprogress.csv' ุฏุฑ ุงูุฏฺฉุณ {index + 1} ุงูุฌุงู ุดุฏ.\")\n",
    "\n",
    "# ุฐุฎุฑู ููุง\n",
    "df_merged.to_csv(GEMINI_OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nโ ุชุญูู (ูููุชุงู ุง ููุง) ุจู ูพุงุงู ุฑุณุฏ ู ูุชุงุฌ ุฏุฑ '{GEMINI_OUTPUT_FILE}' ุฐุฎุฑู ุดุฏูุฏ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11926819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "GEMINI_API_KEY = \"\" \n",
    "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
    "\n",
    "try:\n",
    "    client_gemini = genai.Client()\n",
    "    response = client_gemini.models.generate_content(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        contents=[\"ฺฉ ฺฉููู ูุงุฑุณ ุจุฑุง ุณูุงูุช ฺุณุชุ\"],\n",
    "    )\n",
    "\n",
    "    if response.text and len(response.text.strip()) > 0:\n",
    "        print(\"โ ุชุณุช ุงุชุตุงู ููููุช ุขูุฒ ุจูุฏ ู API ูพุงุณุฎ ุฏุงุฏ!\")\n",
    "        print(f\"   ูพุงุณุฎ ูุฏู: {response.text.strip()}\")\n",
    "    else:\n",
    "        print(\"โ ุชุณุช ุงุชุตุงู ูุงูููู! ูพุงุณุฎ ุฎุงู ุฏุฑุงูุช ุดุฏ.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"โ ุฎุทุง ุงุญุฑุงุฒ ููุช/ุงุชุตุงู: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
