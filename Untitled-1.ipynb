{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡...\n",
      "âœ… ÙØ§ÛŒÙ„ anger.csv Ø¨Ø§ 20069 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: anger\n",
      "âœ… ÙØ§ÛŒÙ„ disgust.csv Ø¨Ø§ 925 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: disgust\n",
      "âœ… ÙØ§ÛŒÙ„ fear.csv Ø¨Ø§ 17624 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: fear\n",
      "âœ… ÙØ§ÛŒÙ„ joy.csv Ø¨Ø§ 28024 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: joy\n",
      "âœ… ÙØ§ÛŒÙ„ sad.csv Ø¨Ø§ 34328 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: sad\n",
      "âœ… ÙØ§ÛŒÙ„ surprise.csv Ø¨Ø§ 12859 Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: surprise\n",
      "\n",
      "------------------------------------\n",
      "âœ… Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: 113829\n",
      "\n",
      "Ûµ Ø³Ø·Ø± ØªØµØ§Ø¯ÙÛŒ Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:\n",
      "                                             Text_Content Sentiment_Label\n",
      "106222  Ø¨Ù‡Ø§Ø±Ù‡ Ø¬Ø§Ù† ØªÛŒØªØ± Ø¨Ø²Ù† Ù…Ø®Ø§Ø²Ù† Ø¢Ù…ÙˆÙ†ÛŒØ§Ú© Ù‡Ù… Ø³Ø±Ú¯Ø±Ø¯Ø§Ù† Ø´Ø¯...        surprise\n",
      "73337    Ø§Ú¯Ø± Ù…ÛŒØ®ÙˆØ§Ø³Øª Ù…ÛŒÚ¯ÙØª Ø±Ø§ÛŒ Ø¨Ø¯ÛŒØ¯! #Ø¯Ø±ÙˆØº_Ù…Ù…Ù†ÙˆØ¹ \\nØ§ÛŒÙ†...             sad\n",
      "50737   Ù…ÙˆÙ„Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ù…Ø§ØŒ Ø§Ø±Ø¨Ø§Ø¨ Ø®ÙˆØ¨ Ø®ÙˆØ¨ÛŒâ€ŒÙ‡Ø§ØŒ Ø¢Ø²Ø§Ø¯Ù‡â€ŒÛŒ Ø§Ø² Ù‡...             joy\n",
      "20100     ØªØ§ Ø­Ø§Ù„Ø§ ØªÙˆ Ø¢ÛŒÙ†Ù‡ Ø¨Ù‡ Ø®ÙˆØ¯Øª Ù†Ú¯Ø§Ù‡ Ú©Ø±Ø¯ÛŒ Ùˆ Ø§ÙˆÙ† Ú†Ù‡Ø±Ù‡...         disgust\n",
      "50393   Ø§Ù…Ø´Ø¨ Ø¯Ø§Ø´ØªÙ… ØªØ±Ø§Ù†Ù‡ Ø³Ø±Ø²Ù…ÛŒÙ† Ù…Ù† Ø§Ø² Ø¯Ø§ÙˆØ¯ Ø³Ø±Ø®ÙˆØ´ Ø®ÙˆØ§Ù†Ù†...             joy\n",
      "\n",
      "ØªÙˆØ²ÛŒØ¹ Ø§Ø­Ø³Ø§Ø³Ø§Øª:\n",
      "Sentiment_Label\n",
      "sad         34328\n",
      "joy         28024\n",
      "anger       20069\n",
      "fear        17624\n",
      "surprise    12859\n",
      "disgust       925\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: 310\n",
      "\n",
      "âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ 'persian_tweets_merged.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV \n",
    "file_names = {\n",
    "    'anger': 'anger.csv',\n",
    "    'disgust': 'disgust.csv',\n",
    "    'fear': 'fear.csv',\n",
    "    'joy': 'joy.csv',\n",
    "    'sad': 'sad.csv',\n",
    "    'surprise': 'surprise.csv'\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "print(\"Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø§Ø¯ØºØ§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡...\")\n",
    "\n",
    "for sentiment, file_name in file_names.items():\n",
    "    try:\n",
    "        # 1. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ø§ ÙØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ù‡Ø¯Ø± (header=0)\n",
    "        df_temp = pd.read_csv(file_name, encoding='utf-8')\n",
    "        \n",
    "        # 2. Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ùˆ ØªØºÛŒÛŒØ± Ù†Ø§Ù… Ø³ØªÙˆÙ† Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ\n",
    "        # Ù…Ø§ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'tweet' Ùˆ 'emotion' Ø±Ø§ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ….\n",
    "        df_temp = df_temp[['tweet', 'emotion']]\n",
    "        \n",
    "        # Ù†Ú©ØªÙ‡: Ú†ÙˆÙ† Ù‡Ø± ÙØ§ÛŒÙ„ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ ÛŒÚ© Ù†ÙˆØ¹ Ø§Ø­Ø³Ø§Ø³ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… ÙØ§ÛŒÙ„) Ø§Ø³ØªØŒ \n",
    "        # Ø³ØªÙˆÙ† 'emotion' Ø¯Ø± ÙˆØ§Ù‚Ø¹ ÙÙ‚Ø· ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ø«Ø§Ø¨Øª (Ù…Ø«Ù„ 'anger') Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø´Øª.\n",
    "        # Ù…Ø§ Ø§Ø² Ø³ØªÙˆÙ† 'emotion' Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ Ú©Ù†ÛŒÙ… Ú©Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.\n",
    "\n",
    "        df_temp = df_temp.rename(columns={'tweet': 'Text_Content', 'emotion': 'Sentiment_Label'})\n",
    "        \n",
    "        all_data.append(df_temp)\n",
    "        print(f\"âœ… ÙØ§ÛŒÙ„ {file_name} Ø¨Ø§ {len(df_temp)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø­Ø³Ø§Ø³: {sentiment}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Ø®Ø·Ø§: ÙØ§ÛŒÙ„ {file_name} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ØªÙ…Ø§Ù… Ø´Ø´ ÙØ§ÛŒÙ„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø¯Ø±Ø³Øª Ù‡Ø³ØªÙ†Ø¯.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {file_name} Ø±Ø® Ø¯Ø§Ø¯: {e}\")\n",
    "\n",
    "# Ø§Ø¯ØºØ§Ù… ØªÙ…Ø§Ù… DataFrameÙ‡Ø§ Ø¨Ù‡ ÛŒÚ© DataFrame Ù†Ù‡Ø§ÛŒÛŒ\n",
    "if all_data:\n",
    "    df_merged = pd.concat(all_data, ignore_index=True)\n",
    "    print(\"\\n------------------------------------\")\n",
    "    print(f\"âœ… Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {len(df_merged)}\")\n",
    "    \n",
    "    # Ù†Ù…Ø§ÛŒØ´ Ûµ Ø³Ø·Ø± ØªØµØ§Ø¯ÙÛŒ Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "    print(\"\\nÛµ Ø³Ø·Ø± ØªØµØ§Ø¯ÙÛŒ Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:\")\n",
    "    print(df_merged.sample(5))\n",
    "    \n",
    "    # Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
    "    print(\"\\nØªÙˆØ²ÛŒØ¹ Ø§Ø­Ø³Ø§Ø³Ø§Øª:\")\n",
    "    print(df_merged['Sentiment_Label'].value_counts())\n",
    "    \n",
    "    # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ\n",
    "    initial_count = len(df_merged)\n",
    "    df_merged.drop_duplicates(subset=['Text_Content', 'Sentiment_Label'], inplace=True)\n",
    "    print(f\"\\nØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: {initial_count - len(df_merged)}\")\n",
    "else:\n",
    "    print(\"Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ØºØ§Ù… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª.\")\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø²ÛŒ DataFrame Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯\n",
    "output_file_path = 'persian_tweets_merged.csv'\n",
    "df_merged.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nâœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ '{output_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03f956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "âœ… Ø³ØªÙˆÙ† Clean_Text Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n",
      "\n",
      "Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ:\n",
      "Ù…ØªÙ† Ø§ØµÙ„ÛŒ: Ø§Ú¯Ø± ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù‡Ù…Ø§Ù† Ù…Ø±Ø¯Ù…ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ø±ÙˆØ² ØªØ´ÛŒÛŒØ¹ Ø´Ù‡ÛŒØ¯ #Ø­Ø§Ø¬_ Ù‚Ø§Ø³Ù… Ø³Ù„ÛŒÙ…Ø§Ù†ÛŒ Ø¨Ù‡ Ø§Ùˆ Ù‚ÙˆÙ„ Ø¯Ø§Ø¯ÛŒØ¯ Ø§Ù†ØªÙ‚Ø§Ù… Ø³Ø®ØªÛŒ Ù…ÛŒ Ú¯ÛŒØ±ÛŒØ¯ Ø±ÙˆØ² Û²Û¸ Ø®Ø±Ø¯Ø§Ø¯ Û±Û´Û°Û° Ø±ÙˆØ² #Ø§Ù†ØªÙ‚Ø§Ù…_ Ø³Ø®Øª Ø§Ø³Øª!\n",
      "#Ø¨Ù‡_Ø¹Ø´Ù‚_Ø§Ù…Ø§Ù…_Ø±Ø¶Ø§ https://t.co/HdBvayzX9W\n",
      "Ù…ØªÙ† ØªÙ…ÛŒØ² Ø´Ø¯Ù‡: Ø§Ú¯Ø± ÙˆØ§Ù‚Ø¹Ø§ Ù‡Ù…Ø§Ù† Ù…Ø±Ø¯Ù…ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ø±ÙˆØ² ØªØ´ÛŒÛŒØ¹ Ø´Ù‡ÛŒØ¯ Ù‚Ø§Ø³Ù… Ø³Ù„ÛŒÙ…Ø§Ù†ÛŒ Ø¨Ù‡ Ø§Ùˆ Ù‚ÙˆÙ„ Ø¯Ø§Ø¯ÛŒØ¯ Ø§Ù†ØªÙ‚Ø§Ù… Ø³Ø®ØªÛŒ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒØ¯ Ø±ÙˆØ² Û²Û¸ Ø®Ø±Ø¯Ø§Ø¯ Û±Û´Û°Û° Ø±ÙˆØ² Ø³Ø®Øª Ø§Ø³Øª\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from hazm import Normalizer\n",
    "\n",
    "# Û±. ØªØ¹Ø±ÛŒÙ Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ²Ø± Hazm\n",
    "normalizer = Normalizer()\n",
    "\n",
    "def clean_and_normalize(text):\n",
    "    # Ø§Ù„Ù) ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø±Ø´ØªÙ‡ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Ø¨) Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Ù¾) Ø­Ø°Ù Ù…Ù†Ø´Ù†â€ŒÙ‡Ø§ (@username) Ùˆ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ (#tag)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Øª) Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ Ùˆ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ ØºÛŒØ± Ø§Ø² Ø­Ø±ÙˆÙ Ùˆ Ø§Ø¹Ø¯Ø§Ø¯\n",
    "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text) \n",
    "    \n",
    "    # Ø«) Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Ø¬) Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Hazm\n",
    "    text = normalizer.normalize(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Ø§Ø¹Ù…Ø§Ù„ ØªØ§Ø¨Ø¹ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø±ÙˆÛŒ Ø³ØªÙˆÙ† Ù…ØªÙ† Ø§Ø¯ØºØ§Ù… Ø´Ø¯Ù‡\n",
    "# ØªÙˆØ¬Ù‡: Ø§Ú¯Ø± Ú©Ø¯ Û±.Ûµ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯ØŒ df_merged Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.\n",
    "df_merged['Clean_Text'] = df_merged['Text_Content'].apply(clean_and_normalize)\n",
    "\n",
    "# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†\n",
    "print(\"\\n------------------------------------\")\n",
    "print(\"âœ… Ø³ØªÙˆÙ† Clean_Text Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\")\n",
    "print(\"\\nÙ†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ:\")\n",
    "sample_row = df_merged.sample(1)\n",
    "print(f\"Ù…ØªÙ† Ø§ØµÙ„ÛŒ: {sample_row['Text_Content'].iloc[0]}\")\n",
    "print(f\"Ù…ØªÙ† ØªÙ…ÛŒØ² Ø´Ø¯Ù‡: {sample_row['Clean_Text'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ae6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ² Ø´Ø¯Ù‡ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ 'persian_tweets_cleaned_for_model.csv' Ø¨Ø§ Ø§ÙÙ†Ú©Ø¯ÛŒÙ†Ú¯ Ø³Ø§Ø²Ú¯Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n",
      "Ø­Ø§Ù„Ø§ Ù…ÛŒ ØªÙˆØ§Ù†ÛŒÙ… ÙˆØ§Ø±Ø¯ ÙØ§Ø² Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆÛŒÙ….\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¬Ø¯Ø¯ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ† Clean_Text\n",
    "# ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ø¯Ø± Ø³Ù„ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
    "\n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ DataFrame Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ² Ø´Ø¯Ù‡\n",
    "final_output_file = 'persian_tweets_cleaned_for_model.csv'\n",
    "\n",
    "# index=False: Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³\n",
    "# encoding='utf-8-sig': Ø§ÛŒÙ† Ù‡Ù…Ø§Ù† UTF-8 with BOM Ø§Ø³Øª Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Excel Ø¨Ù‡ØªØ± Ø§Ø³Øª.\n",
    "df_merged.to_csv(final_output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nâœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ…ÛŒØ² Ø´Ø¯Ù‡ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ '{final_output_file}' Ø¨Ø§ Ø§ÙÙ†Ú©Ø¯ÛŒÙ†Ú¯ Ø³Ø§Ø²Ú¯Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")\n",
    "print(\"Ø­Ø§Ù„Ø§ Ù…ÛŒ ØªÙˆØ§Ù†ÛŒÙ… ÙˆØ§Ø±Ø¯ ÙØ§Ø² Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆÛŒÙ….\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa9fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.\n",
      "\n",
      "Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø­Ø°Ù:\n",
      "['Text_Content', 'Sentiment_Label', 'Clean_Text']\n",
      "âœ… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯. DataFrame Ø¨Ù‡ 2 Ø³ØªÙˆÙ† Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª.\n",
      "\n",
      "âœ… Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ 'persian_tweets_optimized_for_training.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\n",
      "Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Clean_Text Ùˆ Sentiment_Label Ø§Ø³Øª.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ø³Ø§Ø®ØªÛŒÙ…\n",
    "file_path_cleaned = 'persian_tweets_cleaned_for_model.csv'\n",
    "\n",
    "# Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ (Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÙÙ†Ú©Ø¯ÛŒÙ†Ú¯)\n",
    "try:\n",
    "    df_final = pd.read_csv(file_path_cleaned, encoding='utf-8-sig')\n",
    "    print(\"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø±Ø® Ø¯Ø§Ø¯: {e}\")\n",
    "    # Ø§Ú¯Ø± Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±ÛŒØ¯ØŒ ÙÙ‚Ø· encoding='utf-8' Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ÛŒØ¯.\n",
    "    df_final = pd.read_csv(file_path_cleaned, encoding='utf-8')\n",
    "\n",
    "\n",
    "# Û². Ù†Ù…Ø§ÛŒØ´ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯\n",
    "print(\"\\nØ³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø­Ø°Ù:\")\n",
    "print(df_final.columns.tolist())\n",
    "\n",
    "# Û³. Ø­Ø°Ù Ø³ØªÙˆÙ† Text_Content (Ùˆ Ù‡Ø± Ø³ØªÙˆÙ† Ø§Ø¶Ø§ÙÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ù†ÛŒØ³Øª)\n",
    "# Ù…Ø§ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Clean_Text Ùˆ Sentiment_Label Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ….\n",
    "columns_to_keep = ['Clean_Text', 'Sentiment_Label']\n",
    "df_optimized = df_final[columns_to_keep]\n",
    "\n",
    "print(f\"âœ… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯. DataFrame Ø¨Ù‡ {len(df_optimized.columns)} Ø³ØªÙˆÙ† Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª.\")\n",
    "\n",
    "# Û´. Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù‡\n",
    "optimized_file_path = 'persian_tweets_optimized_for_training.csv'\n",
    "df_optimized.to_csv(optimized_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nâœ… Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ '{optimized_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")\n",
    "print(\"Ø§ÛŒÙ† ÙØ§ÛŒÙ„ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Clean_Text Ùˆ Sentiment_Label Ø§Ø³Øª.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ********** Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ **********\n",
    "# Ú©Ù„ÛŒØ¯ API \n",
    "MY_CEREBRAS_API_KEY = \"PLACE_YOUR_ACTUAL_API_KEY_HERE\" \n",
    "\n",
    "# Ù†Ø§Ù… Ù…Ø¯Ù„\n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "\n",
    "# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡\n",
    "FINAL_FILE_NAME = 'cerebras_predictions_final.csv'\n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "\n",
    "try:\n",
    "    # Ø³Ø§Ø®Øª Ú©Ù„Ø§ÛŒÙ†Øª Cerebras\n",
    "    client = Cerebras(api_key=MY_CEREBRAS_API_KEY)\n",
    "    print(f\"âœ… Ú©Ù„Ø§ÛŒÙ†Øª Cerebras Ø¨Ø§ Ù…Ø¯Ù„ {MODEL_NAME} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Cerebras. Ø¢ÛŒØ§ Ú©Ù„ÛŒØ¯ API Ø¯Ø±Ø³Øª Ø§Ø³ØªØŸ: {e}\")\n",
    "\n",
    "# ********** Û². ØªØ¹Ø±ÛŒÙ ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ **********\n",
    "def analyze_sentiment_cerebras(text):\n",
    "    # Prompt Engineering: Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ù…Ø¯Ù„ Instruct\n",
    "    prompt = f\"Ù…ØªÙ† ØªÙˆÛŒÛŒØª ÙØ§Ø±Ø³ÛŒ Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø­Ø³Ø§Ø³ Ø¢Ù† Ø±Ø§ **Ø¯Ù‚ÛŒÙ‚Ø§** Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ† Û¶ Ú©Ù„Ù…Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ùˆ Ø¨Ø§ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†: {', '.join(EMOTIONS)}. Ø§Ø² Ù‡Ø±Ú¯ÙˆÙ†Ù‡ ØªÙˆØ¶ÛŒØ­ØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„ ÛŒØ§ Ù…ØªÙ† Ø§Ø¶Ø§ÙÛŒ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù† Ùˆ **ÙÙ‚Ø· ÛŒÚ© Ú©Ù„Ù…Ù‡** Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.\\nÙ…ØªÙ†: \\\"{text}\\\"\\nØ§Ø­Ø³Ø§Ø³:\"\n",
    "\n",
    "    try:\n",
    "        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=MODEL_NAME,\n",
    "            max_completion_tokens=5, # 5 ØªÙˆÚ©Ù† Ø¨Ø±Ø§ÛŒ ÙÙ‚Ø· ÛŒÚ© Ú©Ù„Ù…Ù‡\n",
    "            temperature=0.01, # Ø¯Ù…Ø§ Ø±Ø§ Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒÛŒÙ† Ù…ÛŒâ€ŒØ¢ÙˆØ±ÛŒÙ… ØªØ§ Ù¾Ø§Ø³Ø® ÙÙ‚Ø· Ø¯Ø³ØªÙˆØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†Ø¯\n",
    "            top_p=0.8,\n",
    "            # stream=False: Ø¨Ù‡ Ø·ÙˆØ± Ù¾ÛŒØ´ ÙØ±Ø¶ Ø¯Ø± SDK ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª\n",
    "        )\n",
    "\n",
    "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø§Ø³Ø®\n",
    "        prediction_raw = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„ Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² 6 Ø¨Ø±Ú†Ø³Ø¨ Ù…Ø§\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotion in prediction_raw:\n",
    "                return emotion\n",
    "\n",
    "        # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ú†ÛŒØ²ÛŒ ØºÛŒØ± Ø§Ø² 6 Ú©Ù„Ù…Ù‡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯\n",
    "        return \"Unknown\" \n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e).lower()\n",
    "        if \"rate limit\" in error_message or \"429\" in error_message:\n",
    "            print(f\"\\nğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Cerebras ÙØ¹Ø§Ù„ Ø´Ø¯! Û±Û° Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…...\")\n",
    "            time.sleep(600) \n",
    "            return \"Rate_Limited\" \n",
    "            \n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# ********** Û³. Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ **********\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ (Ùˆ ÛŒØ§ Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø§Ø² ÙØ§ÛŒÙ„ inprogress)\n",
    "try:\n",
    "    df_llm = pd.read_csv('cerebras_predictions_inprogress.csv', encoding='utf-8-sig')\n",
    "    print(\"Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø§Ø² ÙØ§ÛŒÙ„ inprogress...\")\n",
    "except FileNotFoundError:\n",
    "    df_llm = pd.read_csv('persian_tweets_optimized_for_training.csv', encoding='utf-8-sig')\n",
    "    df_llm['Cerebras_Prediction'] = 'Not_Analyzed' # Ø³ØªÙˆÙ† Ø¬Ø¯ÛŒØ¯\n",
    "\n",
    "\n",
    "# ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ù†ÙˆØ² ØªØ­Ù„ÛŒÙ„ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯\n",
    "remaining_texts_df = df_llm[df_llm['Cerebras_Prediction'].isin(['Not_Analyzed', 'Rate_Limited'])]\n",
    "print(f\"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {len(remaining_texts_df)}\")\n",
    "\n",
    "# Ø­Ù„Ù‚Ù‡ Ø²Ø¯Ù† Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "for index, row in tqdm(remaining_texts_df.iterrows(), total=len(remaining_texts_df), desc=\"ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B\"):\n",
    "    result = analyze_sentiment_cerebras(row['Clean_Text'])\n",
    "    \n",
    "    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ DataFrame Ø§ØµÙ„ÛŒ\n",
    "    df_llm.loc[index, 'Cerebras_Prediction'] = result\n",
    "    \n",
    "    # *Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§*\n",
    "    if (index + 1) % 500 == 0:\n",
    "        df_llm.to_csv('cerebras_predictions_inprogress.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Ø§Ú¯Ø± Ø¨Ù‡ Rate Limit Ø±Ø³ÛŒØ¯ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ Ø­Ù„Ù‚Ù‡ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒÙ… Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒÙ….\n",
    "    if result == \"Rate_Limited\":\n",
    "        print(\"Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø³ÛŒØ¯ÛŒØ¯. Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø´Ø¯.\")\n",
    "        break\n",
    "        \n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "df_llm.to_csv(FINAL_FILE_NAME, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nâœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Cerebras/Qwen API Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± '{FINAL_FILE_NAME}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f549a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 1 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n",
      "Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø§Ø² ÙØ§ÛŒÙ„ 'inprogress'...\n",
      "ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: 109519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B:   0%|          | 2/109519 [00:23<302:49:15,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 1 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 2 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B:   0%|          | 34/109519 [03:13<66:05:03,  2.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 2 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 3 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n",
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 3 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 4 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n",
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 4 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 5 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B:   0%|          | 100/109519 [11:36<464:08:10, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 5 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 6 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B:   0%|          | 101/109519 [11:40<361:16:22, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 6 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 7 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n",
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 7 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "âœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 8 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B:   0%|          | 101/109519 [11:47<213:03:17,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ 8 ÙØ¹Ø§Ù„ Ø´Ø¯!\n",
      "\n",
      "ğŸ›‘ğŸ›‘ ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ÛŒØ§ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±Ø³ÛŒØ¯Ù†Ø¯. Ø§Ù…Ø±ÙˆØ² Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯. ğŸ›‘ğŸ›‘\n",
      "ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø®ÙˆØ±Ø¯Ù†Ø¯. Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø´Ø¯.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 'cerebras_predictions_final.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ********** Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ Ù…Ø¯Ù„ **********\n",
    "\n",
    "CEREBRAS_API_KEYS = [\n",
    "    \"\",  # Ú©Ù„ÛŒØ¯ Ø§ÙˆÙ„ (Ø§ØµÙ„ÛŒ)\n",
    "    \"\", # Ú©Ù„ÛŒØ¯ Ø¯ÙˆÙ… (Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Ø±ÛŒØ¹ Ú©Ø§Ø±)\n",
    "    \n",
    "    # Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯\n",
    "]\n",
    "\n",
    "# Ù†Ø§Ù… Ù…Ø¯Ù„ \n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "\n",
    "# ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ùˆ Ù„ÛŒØ³Øª Ø§Ø­Ø³Ø§Ø³Ø§Øª\n",
    "FINAL_FILE_NAME = 'cerebras_predictions_final.csv'\n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„Ø§ÛŒÙ†Øª Ùˆ Ú©Ù„ÛŒØ¯\n",
    "current_key_index = 0\n",
    "client = None\n",
    "\n",
    "\n",
    "# ********** Û². ØªÙˆØ§Ø¨Ø¹ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒØ¯ Ùˆ Ú©Ù„Ø§ÛŒÙ†Øª **********\n",
    "\n",
    "def get_next_client():\n",
    "    \"\"\"ÛŒÚ© Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ API Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.\"\"\"\n",
    "    global current_key_index, client\n",
    "    \n",
    "    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ù„ÛŒØ¯ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ Ø§Ø³ØªØŸ\n",
    "    if current_key_index >= len(CEREBRAS_API_KEYS):\n",
    "        print(\"\\nğŸ›‘ğŸ›‘ ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ÛŒØ§ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±Ø³ÛŒØ¯Ù†Ø¯. Ø§Ù…Ø±ÙˆØ² Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯. ğŸ›‘ğŸ›‘\")\n",
    "        return None \n",
    "    \n",
    "    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„ÛŒØ¯ ÙØ¹Ù„ÛŒ\n",
    "    api_key = CEREBRAS_API_KEYS[current_key_index]\n",
    "    \n",
    "    try:\n",
    "        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ú©Ù„ÛŒØ¯ Ø±Ø§ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² os.environ Ø¨Ù‡ Cerebras Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
    "        client = Cerebras(api_key=api_key)\n",
    "        print(f\"\\nâœ… Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {current_key_index + 1} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ø§ Ú©Ù„ÛŒØ¯ {current_key_index + 1}: {e}\")\n",
    "        current_key_index += 1 \n",
    "        return get_next_client() # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ\n",
    "\n",
    "\n",
    "def analyze_sentiment_cerebras(text):\n",
    "    \"\"\"ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Cerebras API Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§ÛŒ Rate Limit.\"\"\"\n",
    "    global current_key_index, client\n",
    "    \n",
    "    if client is None:\n",
    "        return \"All_Keys_Used\"\n",
    "    \n",
    "    # Prompt Engineering: Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ù…Ø¯Ù„ Instruct\n",
    "    prompt = (\n",
    "        f\"Ù…ØªÙ† ØªÙˆÛŒÛŒØª ÙØ§Ø±Ø³ÛŒ Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø­Ø³Ø§Ø³ Ø¢Ù† Ø±Ø§ **Ø¯Ù‚ÛŒÙ‚Ø§** Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ† Û¶ Ú©Ù„Ù…Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ùˆ Ø¨Ø§ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†: {', '.join(EMOTIONS)}. \"\n",
    "        f\"Ø§Ø² Ù‡Ø±Ú¯ÙˆÙ†Ù‡ ØªÙˆØ¶ÛŒØ­ØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„ ÛŒØ§ Ù…ØªÙ† Ø§Ø¶Ø§ÙÛŒ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù† Ùˆ **ÙÙ‚Ø· ÛŒÚ© Ú©Ù„Ù…Ù‡** Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.\\n\"\n",
    "        f\"Ù…ØªÙ†: \\\"{text}\\\"\\nØ§Ø­Ø³Ø§Ø³:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=MODEL_NAME,\n",
    "            max_completion_tokens=5, \n",
    "            temperature=0.01,\n",
    "            top_p=0.8,\n",
    "        )\n",
    "\n",
    "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø§Ø³Ø®\n",
    "        prediction_raw = response.choices[0].message.content.strip().lower()\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotion in prediction_raw:\n",
    "                return emotion\n",
    "        return \"Unknown\" # Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„ Ø®Ø§Ø±Ø¬ Ø§Ø² 6 Ø¯Ø³ØªÙ‡ Ù…Ø§ Ø¨ÙˆØ¯\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = str(e).lower()\n",
    "        if \"rate limit\" in error_message or \"429\" in error_message or \"too many requests\" in error_message:\n",
    "            # Ø§Ú¯Ø± Ø¨Ù‡ Rate Limit Ø®ÙˆØ±Ø¯ØŒ Ú©Ù„ÛŒØ¯ Ø±Ø§ Ø¹ÙˆØ¶ Ú©Ù†!\n",
    "            print(f\"\\nğŸ›‘ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® (Rate Limit) Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ Ø´Ù…Ø§Ø±Ù‡ {current_key_index + 1} ÙØ¹Ø§Ù„ Ø´Ø¯!\")\n",
    "            current_key_index += 1 \n",
    "            client = get_next_client() # ØªØ¹Ø±ÛŒÙ Ú©Ù„Ø§ÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ\n",
    "            \n",
    "            if client is None:\n",
    "                 return \"All_Keys_Used\"\n",
    "            \n",
    "            # Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø¬Ø¯ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†\n",
    "            return analyze_sentiment_cerebras(text)\n",
    "            \n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# ********** Û³. Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ **********\n",
    "\n",
    "# ØªØ¹Ø±ÛŒÙ Ú©Ù„Ø§ÛŒÙ†Øª Ø§ÙˆÙ„ÛŒÙ‡\n",
    "client = get_next_client()\n",
    "if client is None:\n",
    "    print(\"Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ ÙØ¹Ø§Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.\")\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ (Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø§Ø² ÙØ§ÛŒÙ„ inprogress ÛŒØ§ Ø´Ø±ÙˆØ¹ Ø§Ø² ÙØ§ÛŒÙ„ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡)\n",
    "try:\n",
    "    df_llm = pd.read_csv('cerebras_predictions_inprogress.csv', encoding='utf-8-sig')\n",
    "    print(\"Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø§Ø² ÙØ§ÛŒÙ„ 'inprogress'...\")\n",
    "except FileNotFoundError:\n",
    "    df_llm = pd.read_csv('persian_tweets_optimized_for_training.csv', encoding='utf-8-sig')\n",
    "    df_llm['Cerebras_Prediction'] = 'Not_Analyzed' # Ø³ØªÙˆÙ† Ø¬Ø¯ÛŒØ¯\n",
    "\n",
    "\n",
    "# ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ù†ÙˆØ² ØªØ­Ù„ÛŒÙ„ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯\n",
    "remaining_texts_df = df_llm[df_llm['Cerebras_Prediction'].isin(['Not_Analyzed', 'Rate_Limited'])]\n",
    "print(f\"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {len(remaining_texts_df)}\")\n",
    "\n",
    "\n",
    "# Ø­Ù„Ù‚Ù‡ Ø²Ø¯Ù† Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "for index, row in tqdm(remaining_texts_df.iterrows(), total=len(remaining_texts_df), desc=\"ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Qwen3-235B\"):\n",
    "    \n",
    "    # Ø§Ú¯Ø± Ú©Ù„Ø§ÛŒÙ†Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³ØªØŒ Ú©Ø§Ø± Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†\n",
    "    if client is None:\n",
    "        break\n",
    "        \n",
    "    result = analyze_sentiment_cerebras(row['Clean_Text'])\n",
    "    \n",
    "    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ DataFrame Ø§ØµÙ„ÛŒ\n",
    "    df_llm.loc[index, 'Cerebras_Prediction'] = result\n",
    "    \n",
    "    # *Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§*\n",
    "    if (index + 1) % 500 == 0:\n",
    "        df_llm.to_csv('cerebras_predictions_inprogress.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Ø§Ú¯Ø± ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø®ÙˆØ±Ø¯Ù†Ø¯ØŒ Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "    if result == \"All_Keys_Used\":\n",
    "        print(\"ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø®ÙˆØ±Ø¯Ù†Ø¯. Ú©Ø§Ø± Ù…ØªÙˆÙ‚Ù Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø´Ø¯.\")\n",
    "        break\n",
    "        \n",
    "# Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ (Ø´Ø§Ù…Ù„ Ù†ØªØ§ÛŒØ¬ Ú©Ø§Ù…Ù„ ÛŒØ§ Ù…ÙˆÙ‚Øª)\n",
    "df_llm.to_csv(FINAL_FILE_NAME, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nâœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± '{FINAL_FILE_NAME}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f03cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù…Ø±Ø­Ù„Ù‡ Û±: Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ².\n",
      "\n",
      "âŒ Ø®Ø·Ø§ÛŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª ÛŒØ§ Ø§ØªØµØ§Ù„ Ø±Ø® Ø¯Ø§Ø¯:\n",
      "Error code: 429 - {'message': \"We're experiencing high traffic right now! Please try again soon.\", 'type': 'too_many_requests_error', 'param': 'queue', 'code': 'queue_exceeded'}\n"
     ]
    }
   ],
   "source": [
    "from cerebras.cloud.sdk import Cerebras\n",
    "import os\n",
    "\n",
    "# !!! Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯ !!!\n",
    "MY_CEREBRAS_API_KEY = \"csk-n9d4tvp6m4855cn93yw5r4cr2ev2kcedy93neh4rhfvecd5j\"\n",
    "MODEL_NAME = \"qwen-3-235b-a22b-instruct-2507\" \n",
    "EMOTIONS = [\"joy\", \"sad\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "test_text = \"ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø¬Ø¯ÛŒØ¯ Ø±Ø§Ø¶ÛŒ Ù‡Ø³ØªÙ… Ùˆ Ø­Ø³ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ù….\"\n",
    "test_prompt = (\n",
    "    f\"Ù…ØªÙ† ØªÙˆÛŒÛŒØª ÙØ§Ø±Ø³ÛŒ Ø²ÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø­Ø³Ø§Ø³ Ø¢Ù† Ø±Ø§ **Ø¯Ù‚ÛŒÙ‚Ø§** Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ø§ÛŒÙ† Û¶ Ú©Ù„Ù…Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ùˆ Ø¨Ø§ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†: {', '.join(EMOTIONS)}. \"\n",
    "    f\"Ø§Ø² Ù‡Ø±Ú¯ÙˆÙ†Ù‡ ØªÙˆØ¶ÛŒØ­ØŒ Ù†Ù‚Ù„ Ù‚ÙˆÙ„ ÛŒØ§ Ù…ØªÙ† Ø§Ø¶Ø§ÙÛŒ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù† Ùˆ **ÙÙ‚Ø· ÛŒÚ© Ú©Ù„Ù…Ù‡** Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†.\\n\"\n",
    "    f\"Ù…ØªÙ†: \\\"{test_text}\\\"\\nØ§Ø­Ø³Ø§Ø³:\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Û±. Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª\n",
    "    client = Cerebras(api_key=MY_CEREBRAS_API_KEY)\n",
    "    print(\"âœ… Ù…Ø±Ø­Ù„Ù‡ Û±: Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ².\")\n",
    "    \n",
    "    # Û². Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional Persian emotion classification system that only returns one word.\"},\n",
    "            {\"role\": \"user\", \"content\": test_prompt}\n",
    "        ],\n",
    "        model=MODEL_NAME,\n",
    "        max_completion_tokens=5, \n",
    "        temperature=0.01,\n",
    "        top_p=0.8,\n",
    "    )\n",
    "    \n",
    "    # Û³. Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡\n",
    "    print(\"âœ… Ù…Ø±Ø­Ù„Ù‡ Û²: Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ².\")\n",
    "    print(\"\\nÙ†ØªÛŒØ¬Ù‡ Ù…Ø¯Ù„ (Ø§Ø­Ø³Ø§Ø³):\", response.choices[0].message.content.strip())\n",
    "\n",
    "except Exception as e:\n",
    "    # Û´. Ú†Ø§Ù¾ Ø®Ø·Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚\n",
    "    print(\"\\nâŒ Ø®Ø·Ø§ÛŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª ÛŒØ§ Ø§ØªØµØ§Ù„ Ø±Ø® Ø¯Ø§Ø¯:\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
